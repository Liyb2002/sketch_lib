#!/usr/bin/env python3
"""
reconstruct_3d_vggt.py - Runs the VGGT model for 3D reconstruction
from a set of realistic views generated by Zero123++.

Input:  sketch/views/ (Contains view_0.png, view_1.png, etc.)
Output: sketch/3d_reconstruction/
    1. fused_model.ply (3D Point Cloud)
    2. *_cam.json (Inferred Camera Extrinsics/Intrinsics)
    3. *_verification_render.png (Verification Renders)
    4. *_overlay.png (Input + Render overlay)
    5. vggt_shape.glb (Mesh, <= 5000 faces)

NOTE: Depth maps are NOT saved in this version.
"""
import os
import sys
import json
import numpy as np
import torch
import cv2
import open3d as o3d
from PIL import Image
from pathlib import Path

# Optional (fallback GLB writing if Open3D can't write .glb on your version)
try:
    import trimesh
except Exception:
    trimesh = None

# -----------------------------------------------------------------------------
# 1. SETUP & IMPORTS
# -----------------------------------------------------------------------------
THIS_DIR = os.path.dirname(os.path.abspath(__file__))

# VGGT is installed under /packages/vggt
VGGT_REPO_ROOT = os.path.join(THIS_DIR, "packages", "vggt")
sys.path.insert(0, VGGT_REPO_ROOT)

# Import VGGT modules
try:
    from vggt.models.vggt import VGGT
    from vggt.utils.load_fn import load_and_preprocess_images
    from vggt.utils.pose_enc import pose_encoding_to_extri_intri
    from vggt.utils.geometry import unproject_depth_map_to_point_map
except ImportError:
    print("Error: Could not import VGGT. Make sure the 'vggt' folder is present and accessible.")
    sys.exit(1)

ROOT_SKETCH_FOLDER = Path(THIS_DIR) / "sketch"
INPUT_VIEWS_DIR = ROOT_SKETCH_FOLDER / "views"
OUTPUT_DIR = ROOT_SKETCH_FOLDER / "3d_reconstruction"

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BG_THRESHOLD = 0.95  # Brightness threshold for mask (assumes white background)
MAX_POINTS = 500_000

# Mesh settings
GLB_NAME = "vggt_shape.glb"
MAX_FACES = 5_000
POISSON_DEPTH = 9          # increase for more detail, slower
NORMAL_KNN = 30            # normal estimation neighborhood
DENSITY_CROP_Q = 0.02      # remove lowest-density vertices (0.01-0.05 typical)

# -----------------------------------------------------------------------------
# 2. HELPERS
# -----------------------------------------------------------------------------
def normalize_depth_tensor_to_nhw(depth_tensor):
    """Converts torch depth tensor to (N, H, W) numpy array."""
    d = depth_tensor.detach().cpu().numpy()
    if d.ndim == 4 and d.shape[1] == 1:
        d = d[:, 0]
    elif d.ndim == 4 and d.shape[-1] == 1:
        d = d[..., 0]
    return d

def build_object_masks(view_paths, target_h, target_w):
    """
    Creates a boolean mask where True = Object, False = White Background.
    Uses BG_THRESHOLD (0.95 luminance) to aggressively mask the background.
    """
    masks = []
    for p in view_paths:
        img = Image.open(p).convert("RGB")
        img = img.resize((target_w, target_h), Image.Resampling.BILINEAR)
        rgb = np.array(img).astype(np.float32) / 255.0
        gray = rgb.mean(axis=2)
        mask = gray < BG_THRESHOLD
        masks.append(mask)
    return np.stack(masks, axis=0)

def render_verification(points, colors, w2c_4x4, K, H, W, save_path):
    """
    Renders the point cloud back to the camera view to verify alignment.

    Assumes:
      - points are in WORLD coordinates (N, 3)
      - w2c_4x4 is WORLD-to-CAMERA extrinsic (4x4)
      - K is intrinsics (3x3)
    """
    ones = np.ones((len(points), 1), dtype=np.float32)
    pts_hom = np.hstack([points.astype(np.float32), ones])  # (N,4)
    pts_cam = (w2c_4x4 @ pts_hom.T).T  # (N,4)

    x, y, z = pts_cam[:, 0], pts_cam[:, 1], pts_cam[:, 2]

    valid_z = z > 0.01
    if not np.any(valid_z):
        print(f"[WARN] No valid points after z>0 filter for {save_path.name}")
        canvas = np.full((H, W, 3), 255, dtype=np.uint8)
        cv2.imwrite(str(save_path), cv2.cvtColor(canvas, cv2.COLOR_RGB2BGR))
        return

    x, y, z = x[valid_z], y[valid_z], z[valid_z]
    cur_colors = colors[valid_z]

    fx, fy = K[0, 0], K[1, 1]
    cx, cy = K[0, 2], K[1, 2]

    u = (x * fx / z) + cx
    v = (y * fy / z) + cy

    u = np.round(u).astype(int)
    v = np.round(v).astype(int)

    valid_px = (u >= 0) & (u < W) & (v >= 0) & (v < H)
    if not np.any(valid_px):
        print(f"[WARN] No valid pixels inside frame for {save_path.name}")
        canvas = np.full((H, W, 3), 255, dtype=np.uint8)
        cv2.imwrite(str(save_path), cv2.cvtColor(canvas, cv2.COLOR_RGB2BGR))
        return

    u, v, z = u[valid_px], v[valid_px], z[valid_px]
    cur_colors = cur_colors[valid_px]

    canvas = np.full((H, W, 3), 255, dtype=np.uint8)

    # Painter's algorithm: furthest first, nearest last
    sort_idx = np.argsort(-z)
    uu = u[sort_idx]
    vv = v[sort_idx]
    cc = (cur_colors[sort_idx] * 255).astype(np.uint8)

    canvas[vv, uu] = cc
    cv2.imwrite(str(save_path), cv2.cvtColor(canvas, cv2.COLOR_RGB2BGR))

def save_overlay(input_img_path, render_img_path, overlay_out_path, alpha=0.55):
    """
    Saves an overlay image of render on top of input.
    alpha = weight of input; (1-alpha) = weight of render.
    """
    inp = Image.open(input_img_path).convert("RGB")
    rnd = Image.open(render_img_path).convert("RGB")

    if rnd.size != inp.size:
        rnd = rnd.resize(inp.size, Image.Resampling.BILINEAR)

    inp_np = np.array(inp).astype(np.float32)
    rnd_np = np.array(rnd).astype(np.float32)

    overlay = alpha * inp_np + (1.0 - alpha) * rnd_np
    overlay = np.clip(overlay, 0, 255).astype(np.uint8)
    Image.fromarray(overlay).save(overlay_out_path)

def pointcloud_to_glb_mesh(pcd: o3d.geometry.PointCloud, out_glb_path: Path):
    """
    Builds a mesh from a point cloud, decimates to <= MAX_FACES, and writes GLB.
    Strategy:
      1) Try Poisson
      2) If Poisson fails, fallback to alpha shape
    """
    if len(pcd.points) < 3000:
        print("[WARN] Too few points for meshing; skipping GLB export.")
        return

    # --- light voxel downsample for stability/speed ---
    bbox = pcd.get_axis_aligned_bounding_box()
    diag = np.linalg.norm(bbox.get_extent())
    voxel = max(diag / 512.0, 1e-4)
    pcd_ds = pcd.voxel_down_sample(voxel_size=voxel)

    if len(pcd_ds.points) < 3000:
        pcd_ds = pcd  # fallback

    # --- normals (required for Poisson) ---
    try:
        pcd_ds.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=diag/50.0, max_nn=60))
        pcd_ds.normalize_normals()
    except Exception as e:
        print(f"[WARN] Normal estimation failed: {e}")

    aabb = pcd_ds.get_axis_aligned_bounding_box()

    mesh = None

    # =======================
    # 1) Poisson attempt
    # =======================
    try:
        print("[MESH] Poisson reconstruction...")
        mesh_poisson, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(
            pcd_ds, depth=POISSON_DEPTH
        )
        if mesh_poisson is not None and len(mesh_poisson.triangles) > 0:
            mesh = mesh_poisson

            # Remove low-density vertices (helps floaters)
            if densities is not None:
                dens = np.asarray(densities)
                if dens.size > 0:
                    thr = np.quantile(dens, DENSITY_CROP_Q)
                    keep = dens >= thr
                    mesh = mesh.remove_vertices_by_mask(~keep)

            # Crop to AABB (only if mesh exists)
            mesh = mesh.crop(aabb)

    except Exception as e:
        print(f"[WARN] Poisson failed: {e}")
        mesh = None

    # =======================
    # 2) Fallback: Alpha shape
    # =======================
    if mesh is None or len(mesh.triangles) == 0:
        if len(pcd_ds.points) < 5000:
            print("[WARN] Not enough points for alpha-shape fallback; skipping GLB export.")
            return

        # alpha heuristic from scale
        alpha = max(diag / 40.0, 1e-3)
        try:
            print(f"[MESH] Fallback alpha-shape (alpha={alpha:.6f})...")
            mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(pcd_ds, alpha)
            if mesh is None or len(mesh.triangles) == 0:
                print("[WARN] Alpha-shape produced empty mesh; skipping GLB export.")
                return
            mesh = mesh.crop(aabb)
        except Exception as e:
            print(f"[WARN] Alpha-shape failed: {e}")
            return

    # --- cleanup ---
    mesh.remove_degenerate_triangles()
    mesh.remove_duplicated_triangles()
    mesh.remove_duplicated_vertices()
    mesh.remove_non_manifold_edges()

    tri_count = len(mesh.triangles)
    print(f"[MESH] Triangles before decimation: {tri_count}")

    # --- decimate to <= MAX_FACES ---
    if tri_count > MAX_FACES:
        print(f"[MESH] Decimating to <= {MAX_FACES} faces...")
        mesh = mesh.simplify_quadric_decimation(target_number_of_triangles=MAX_FACES)
        mesh.remove_degenerate_triangles()
        mesh.remove_duplicated_triangles()
        mesh.remove_duplicated_vertices()
        mesh.remove_non_manifold_edges()

    mesh.compute_vertex_normals()
    print(f"[MESH] Triangles after decimation:  {len(mesh.triangles)}")

    # --- write GLB ---
    wrote = False
    try:
        wrote = o3d.io.write_triangle_mesh(str(out_glb_path), mesh)
    except Exception:
        wrote = False

    if wrote:
        print(f"[MESH] Saved mesh: {out_glb_path}")
        return

    # Fallback: trimesh export
    if trimesh is None:
        print("[WARN] Open3D couldn't write .glb and trimesh is unavailable; skipping GLB export.")
        return

    print("[MESH] Open3D couldn't write .glb; using trimesh fallback...")
    v = np.asarray(mesh.vertices)
    f = np.asarray(mesh.triangles)
    tm = trimesh.Trimesh(vertices=v, faces=f, process=False)
    tm.export(str(out_glb_path))
    print(f"[MESH] Saved mesh (trimesh): {out_glb_path}")

# -----------------------------------------------------------------------------
# 3. MAIN PIPELINE
# -----------------------------------------------------------------------------
def main():
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    view_paths = sorted(list(INPUT_VIEWS_DIR.glob("*.png")))
    if not view_paths:
        print(f"No images found in {INPUT_VIEWS_DIR}")
        print("Ensure you have run the Zero123++ script successfully.")
        return

    print(f"Loading {len(view_paths)} images from {INPUT_VIEWS_DIR.name}...")
    images = load_and_preprocess_images([str(p) for p in view_paths]).to(DEVICE)  # (N, 3, H, W)
    H, W = images.shape[-2:]
    print(f"Model input size: H={H}, W={W}")

    print("Running VGGT Model...")
    model = VGGT.from_pretrained("facebook/VGGT-1B").to(DEVICE)
    model.eval()

    with torch.no_grad():
        images_batch = images.unsqueeze(0)  # (1, N, 3, H, W)
        tokens, idx = model.aggregator(images_batch)

        pose_enc = model.camera_head(tokens)[-1]
        extrinsics, intrinsics = pose_encoding_to_extri_intri(pose_enc, (H, W))

        # We use depth only to unproject into 3D points; we do NOT save it.
        depth_tensor, _ = model.depth_head(tokens, images_batch, idx)

    extrinsics_np = extrinsics.squeeze(0).cpu().numpy()  # (N, 3, 4) W2C
    intrinsics_np = intrinsics.squeeze(0).cpu().numpy()  # (N, 3, 3)
    depth_np = normalize_depth_tensor_to_nhw(depth_tensor.squeeze(0))  # (N, H, W)

    print("Extrinsics shape:", extrinsics_np.shape)
    print("Intrinsics shape:", intrinsics_np.shape)
    print("Depth shape:     ", depth_np.shape, "(not saved)")

    print("\nGenerating Point Cloud...")
    masks = build_object_masks([str(p) for p in view_paths], H, W)
    depth_masked = depth_np.copy()
    depth_masked[~masks] = 0.0
    depth_for_unproj = depth_masked[..., None]  # (N, H, W, 1)

    point_map = unproject_depth_map_to_point_map(
        depth_for_unproj,
        extrinsics_np,
        intrinsics_np
    )  # (N, H, W, 3)

    points_all = point_map.reshape(-1, 3)

    colors_list = []
    for p in view_paths:
        img = Image.open(p).convert("RGB").resize((W, H))
        colors_list.append(np.array(img).reshape(-1, 3) / 255.0)
    colors_all = np.concatenate(colors_list, axis=0)

    valid_mask = np.isfinite(points_all).all(axis=1) & (np.abs(points_all).sum(axis=1) > 0)
    points_final = points_all[valid_mask]
    colors_final = colors_all[valid_mask]

    print(f"Total raw points:     {points_all.shape[0]}")
    print(f"Valid nonzero points: {points_final.shape[0]}")

    if len(points_final) > MAX_POINTS:
        idx_ds = np.random.choice(len(points_final), MAX_POINTS, replace=False)
        points_final = points_final[idx_ds]
        colors_final = colors_final[idx_ds]
        print(f"Downsampled to {MAX_POINTS} points")

    ply_path = OUTPUT_DIR / "fused_model.ply"
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(points_final)
    pcd.colors = o3d.utility.Vector3dVector(colors_final)
    o3d.io.write_point_cloud(str(ply_path), pcd)
    print(f"Saved fused 3D point cloud: {ply_path}")

    # NEW: build and save a <=5000-face mesh as GLB
    # glb_path = OUTPUT_DIR / GLB_NAME
    # pointcloud_to_glb_mesh(pcd, glb_path)

    print("\nSaving Cameras and Verifying Alignment (W2C)...")
    for i, vp in enumerate(view_paths):
        name = vp.stem

        w2c_3x4 = extrinsics_np[i]
        K = intrinsics_np[i]

        w2c_4x4 = np.eye(4, dtype=np.float32)
        w2c_4x4[:3, :4] = w2c_3x4

        cam_data = {"extrinsics_w2c": w2c_4x4.tolist(), "intrinsics": K.tolist()}
        json_path = OUTPUT_DIR / f"{name}_cam.json"
        with open(json_path, "w") as f:
            json.dump(cam_data, f, indent=4)

        render_path = OUTPUT_DIR / f"{name}_verification_render.png"
        render_verification(points_final, colors_final, w2c_4x4, K, H, W, render_path)

        overlay_path = OUTPUT_DIR / f"{name}_overlay.png"
        save_overlay(vp, render_path, overlay_path, alpha=0.55)

        print(f"  - View {i}:")
        print(f"      JSON:    {json_path.name}")
        print(f"      Render:  {render_path.name}")
        print(f"      Overlay: {overlay_path.name}")

    print(f"\nSuccess! Check {OUTPUT_DIR} for:")
    print("  - fused_model.ply (3D Shape)")
    print("  - vggt_shape.glb (Mesh, <= 5000 faces)")
    print("  - *_cam.json (Inferred Camera Positions)")
    print("  - *_verification_render.png (Verification Renders)")
    print("  - *_overlay.png (Input + Render overlay)")
    print("  - (Depth maps are NOT saved)")

if __name__ == "__main__":
    main()